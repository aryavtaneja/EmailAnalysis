{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('olddata.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Body</th>\n",
       "      <th>Replied To</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINEET, Remember To Purchase Your Getaway Star...</td>\n",
       "      <td>Hilton Grand Vacations &lt;hgv@travel2.hiltongran...</td>\n",
       "      <td>1.683869e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td>Your 3-Night Vacation Can Get You $100 Towards...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spring Recital next Saturday May 20th at 5:00</td>\n",
       "      <td>Andrew Bushnell &lt;fiddlersroof@outlook.com&gt;</td>\n",
       "      <td>1.683868e+09</td>\n",
       "      <td>UNREAD, IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Class of 2028] Save the date - 7th Grade End ...</td>\n",
       "      <td>Tushar Gupta &lt;m@mail1.veracross.com&gt;</td>\n",
       "      <td>1.683867e+09</td>\n",
       "      <td>UNREAD, IMPORTANT, CATEGORY_UPDATES, INBOX,</td>\n",
       "      <td>Hello class of 2028 families, \\r\\nWe are plann...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Mantri Celestia] Special Notice: Power Shutdo...</td>\n",
       "      <td>Mantri Celestia helpdesk &lt;donotreply@apnacompl...</td>\n",
       "      <td>1.683866e+09</td>\n",
       "      <td>UNREAD, CATEGORY_UPDATES, INBOX,</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We're Giving You Up to 40% Off Sale Styles</td>\n",
       "      <td>Banana Republic &lt;bananarepublic@email.bananare...</td>\n",
       "      <td>1.683864e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td>\\r\\n\\r\\nWe're Giving You Up to 40% Off Sale St...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Subject   \n",
       "0  VINEET, Remember To Purchase Your Getaway Star...  \\\n",
       "1      Spring Recital next Saturday May 20th at 5:00   \n",
       "2  [Class of 2028] Save the date - 7th Grade End ...   \n",
       "3  [Mantri Celestia] Special Notice: Power Shutdo...   \n",
       "4         We're Giving You Up to 40% Off Sale Styles   \n",
       "\n",
       "                                              Sender          Date   \n",
       "0  Hilton Grand Vacations <hgv@travel2.hiltongran...  1.683869e+09  \\\n",
       "1         Andrew Bushnell <fiddlersroof@outlook.com>  1.683868e+09   \n",
       "2               Tushar Gupta <m@mail1.veracross.com>  1.683867e+09   \n",
       "3  Mantri Celestia helpdesk <donotreply@apnacompl...  1.683866e+09   \n",
       "4  Banana Republic <bananarepublic@email.bananare...  1.683864e+09   \n",
       "\n",
       "                                          Labels   \n",
       "0           CATEGORY_PROMOTIONS, UNREAD, INBOX,   \\\n",
       "1  UNREAD, IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "2   UNREAD, IMPORTANT, CATEGORY_UPDATES, INBOX,    \n",
       "3              UNREAD, CATEGORY_UPDATES, INBOX,    \n",
       "4           CATEGORY_PROMOTIONS, UNREAD, INBOX,    \n",
       "\n",
       "                                                Body  Replied To  \n",
       "0  Your 3-Night Vacation Can Get You $100 Towards...           0  \n",
       "1                                                              0  \n",
       "2  Hello class of 2028 families, \\r\\nWe are plann...           0  \n",
       "3                                                              0  \n",
       "4  \\r\\n\\r\\nWe're Giving You Up to 40% Off Sale St...           0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all rows where the date is None\n",
    "df[df['Date'].isnull()]\n",
    "\n",
    "#delete these rows\n",
    "df = df.dropna(subset=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "870\n"
     ]
    }
   ],
   "source": [
    "#print the number of Replied To emails\n",
    "print(len(df[df['Replied To'] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Replied To\n",
       "0    870\n",
       "1    870\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby('Replied To').head(870)\n",
    "df.value_counts('Replied To')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Sender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Body</th>\n",
       "      <th>Replied To</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36120</th>\n",
       "      <td>Fw: Khushboo - Inquiry Regarding Aryav, Sophomore</td>\n",
       "      <td>Khushboo Taneja &lt;khushboo.taneja@live.com&gt;</td>\n",
       "      <td>1.655744e+09</td>\n",
       "      <td>IMPORTANT, STARRED, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td>\\r\\n________________________________\\r\\nFrom: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>40% off all our favorite styles + an extra 20%</td>\n",
       "      <td>Banana Republic Factory &lt;bananarepublicfactory...</td>\n",
       "      <td>1.683195e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td>\\r\\n\\r\\nBanana Republic Factory Store\\r\\nhttps...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36130</th>\n",
       "      <td>Fwd: Solomon Admissions Consulting - packages</td>\n",
       "      <td>Khushboo Taneja &lt;khushboo.taneja@live.com&gt;</td>\n",
       "      <td>1.655738e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53789</th>\n",
       "      <td>Re: [Greystone]: Community Trip Saver App survey</td>\n",
       "      <td>Vibha Rathi &lt;vibharathi@gmail.com&gt;</td>\n",
       "      <td>1.641589e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_FORUMS, INBOX,</td>\n",
       "      <td>Dear neighbors,\\r\\nThanks for filling our our ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>There’s still time to ship for M-Day</td>\n",
       "      <td>DoorDash &lt;no-reply@doordash.com&gt;</td>\n",
       "      <td>1.683473e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td>DoorDash Get 50% off shipped flowers &amp; sweets ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7775</th>\n",
       "      <td>Fw: Permission form for March 12th MS Debate t...</td>\n",
       "      <td>Khushboo Taneja &lt;khushboo.taneja@live.com&gt;</td>\n",
       "      <td>1.677642e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>Etsy, Inc. (ETSY) Q1 2023 Earnings Call Transc...</td>\n",
       "      <td>SA Analysis &lt;account@seekingalpha.com&gt;</td>\n",
       "      <td>1.683165e+09</td>\n",
       "      <td>UNREAD, CATEGORY_UPDATES, INBOX,</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html xmlns:v=\"urn:schemas-micr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.683451e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td>Hidden bathroom remodeling costs to avoid. Plu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53414</th>\n",
       "      <td>Professional Resume Services -- First Draft At...</td>\n",
       "      <td>Rene Hart &lt;rene@professionalresumeservices.com&gt;</td>\n",
       "      <td>1.641944e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34355</th>\n",
       "      <td>RE: GM at Taj Vivanta, Dwarka?</td>\n",
       "      <td>Anubhav Makhija &lt;anubhav.makhija@tajhotels.com&gt;</td>\n",
       "      <td>1.657110e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26922</th>\n",
       "      <td>Re: Checking in</td>\n",
       "      <td>pranoy mohapatra &lt;pranoym1@gmail.com&gt;</td>\n",
       "      <td>1.662902e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td>Excellent work, Aryav! Yes, hearing similarly ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>$29 NEW Glasshouse Diffusers - 48 HOURS ONLY</td>\n",
       "      <td>\"OZSALE.com.au\" &lt;members@email.ozsale.com.au&gt;</td>\n",
       "      <td>1.683328e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38322</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.654029e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td>Two-tone kitchen with a butcher block island f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>You’re doing your Home Décor wrong. Tap for a ...</td>\n",
       "      <td>Zoomin &lt;no-reply@zoomin.com&gt;</td>\n",
       "      <td>1.683287e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td>Decode your décor style &amp; enjoy Flat 30% off.\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33379</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.657816e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, UNREAD, INBOX,</td>\n",
       "      <td>Breathe new life into your space with our best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>TSLA: Tesla boosts prices in China on some Mod...</td>\n",
       "      <td>SA Breaking News &lt;account@seekingalpha.com&gt;</td>\n",
       "      <td>1.683285e+09</td>\n",
       "      <td>UNREAD, CATEGORY_UPDATES, INBOX,</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;&lt;html xmlns:v=\"urn:schemas-micr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47751</th>\n",
       "      <td>Re: Call w. Spotnana</td>\n",
       "      <td>Shannah Hackett &lt;shannah@spotnana.com&gt;</td>\n",
       "      <td>1.646674e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td>Sorry about that! Please ignore my email.\\r\\n\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35840</th>\n",
       "      <td>Re: Re:</td>\n",
       "      <td>Khushboo Taneja &lt;khushboo.taneja@live.com&gt;</td>\n",
       "      <td>1.655921e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td>Ya Ivywise sent me a list of their coaches and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Time is Running Out...Member-Only Savings ENDS...</td>\n",
       "      <td>Costco Wholesale &lt;Costco@online.costco.com&gt;</td>\n",
       "      <td>1.683471e+09</td>\n",
       "      <td>CATEGORY_PROMOTIONS, IMPORTANT, INBOX,</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39366</th>\n",
       "      <td>Re: Tanny paid you $13.20 on Splitwise</td>\n",
       "      <td>Shaiwal Singh &lt;shaiwal@gmail.com&gt;</td>\n",
       "      <td>1.653253e+09</td>\n",
       "      <td>IMPORTANT, CATEGORY_PERSONAL, INBOX,</td>\n",
       "      <td>Hi Vineet,\\r\\n\\r\\nLooks like the venmo payment...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Subject   \n",
       "36120  Fw: Khushboo - Inquiry Regarding Aryav, Sophomore  \\\n",
       "834       40% off all our favorite styles + an extra 20%   \n",
       "36130      Fwd: Solomon Admissions Consulting - packages   \n",
       "53789   Re: [Greystone]: Community Trip Saver App survey   \n",
       "493                 There’s still time to ship for M-Day   \n",
       "7775   Fw: Permission form for March 12th MS Debate t...   \n",
       "850    Etsy, Inc. (ETSY) Q1 2023 Earnings Call Transc...   \n",
       "520                                                        \n",
       "53414  Professional Resume Services -- First Draft At...   \n",
       "34355                     RE: GM at Taj Vivanta, Dwarka?   \n",
       "26922                                    Re: Checking in   \n",
       "617         $29 NEW Glasshouse Diffusers - 48 HOURS ONLY   \n",
       "38322                                                      \n",
       "695    You’re doing your Home Décor wrong. Tap for a ...   \n",
       "33379                                                      \n",
       "699    TSLA: Tesla boosts prices in China on some Mod...   \n",
       "47751                               Re: Call w. Spotnana   \n",
       "35840                                            Re: Re:   \n",
       "496    Time is Running Out...Member-Only Savings ENDS...   \n",
       "39366             Re: Tanny paid you $13.20 on Splitwise   \n",
       "\n",
       "                                                  Sender          Date   \n",
       "36120         Khushboo Taneja <khushboo.taneja@live.com>  1.655744e+09  \\\n",
       "834    Banana Republic Factory <bananarepublicfactory...  1.683195e+09   \n",
       "36130         Khushboo Taneja <khushboo.taneja@live.com>  1.655738e+09   \n",
       "53789                 Vibha Rathi <vibharathi@gmail.com>  1.641589e+09   \n",
       "493                     DoorDash <no-reply@doordash.com>  1.683473e+09   \n",
       "7775          Khushboo Taneja <khushboo.taneja@live.com>  1.677642e+09   \n",
       "850               SA Analysis <account@seekingalpha.com>  1.683165e+09   \n",
       "520                                                       1.683451e+09   \n",
       "53414    Rene Hart <rene@professionalresumeservices.com>  1.641944e+09   \n",
       "34355    Anubhav Makhija <anubhav.makhija@tajhotels.com>  1.657110e+09   \n",
       "26922              pranoy mohapatra <pranoym1@gmail.com>  1.662902e+09   \n",
       "617        \"OZSALE.com.au\" <members@email.ozsale.com.au>  1.683328e+09   \n",
       "38322                                                     1.654029e+09   \n",
       "695                         Zoomin <no-reply@zoomin.com>  1.683287e+09   \n",
       "33379                                                     1.657816e+09   \n",
       "699          SA Breaking News <account@seekingalpha.com>  1.683285e+09   \n",
       "47751             Shannah Hackett <shannah@spotnana.com>  1.646674e+09   \n",
       "35840         Khushboo Taneja <khushboo.taneja@live.com>  1.655921e+09   \n",
       "496          Costco Wholesale <Costco@online.costco.com>  1.683471e+09   \n",
       "39366                  Shaiwal Singh <shaiwal@gmail.com>  1.653253e+09   \n",
       "\n",
       "                                               Labels   \n",
       "36120  IMPORTANT, STARRED, CATEGORY_PERSONAL, INBOX,   \\\n",
       "834              CATEGORY_PROMOTIONS, UNREAD, INBOX,    \n",
       "36130           IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "53789             IMPORTANT, CATEGORY_FORUMS, INBOX,    \n",
       "493              CATEGORY_PROMOTIONS, UNREAD, INBOX,    \n",
       "7775            IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "850                 UNREAD, CATEGORY_UPDATES, INBOX,    \n",
       "520              CATEGORY_PROMOTIONS, UNREAD, INBOX,    \n",
       "53414           IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "34355           IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "26922           IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "617              CATEGORY_PROMOTIONS, UNREAD, INBOX,    \n",
       "38322            CATEGORY_PROMOTIONS, UNREAD, INBOX,    \n",
       "695              CATEGORY_PROMOTIONS, UNREAD, INBOX,    \n",
       "33379            CATEGORY_PROMOTIONS, UNREAD, INBOX,    \n",
       "699                 UNREAD, CATEGORY_UPDATES, INBOX,    \n",
       "47751           IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "35840           IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "496           CATEGORY_PROMOTIONS, IMPORTANT, INBOX,    \n",
       "39366           IMPORTANT, CATEGORY_PERSONAL, INBOX,    \n",
       "\n",
       "                                                    Body  Replied To  \n",
       "36120  \\r\\n________________________________\\r\\nFrom: ...           1  \n",
       "834    \\r\\n\\r\\nBanana Republic Factory Store\\r\\nhttps...           0  \n",
       "36130                                                              1  \n",
       "53789  Dear neighbors,\\r\\nThanks for filling our our ...           1  \n",
       "493    DoorDash Get 50% off shipped flowers & sweets ...           0  \n",
       "7775                                                               1  \n",
       "850    <!DOCTYPE html><html xmlns:v=\"urn:schemas-micr...           0  \n",
       "520    Hidden bathroom remodeling costs to avoid. Plu...           1  \n",
       "53414                                                              1  \n",
       "34355                                                              1  \n",
       "26922  Excellent work, Aryav! Yes, hearing similarly ...           1  \n",
       "617                                                                0  \n",
       "38322  Two-tone kitchen with a butcher block island f...           1  \n",
       "695    Decode your décor style & enjoy Flat 30% off.\\...           0  \n",
       "33379  Breathe new life into your space with our best...           1  \n",
       "699    <!DOCTYPE html><html xmlns:v=\"urn:schemas-micr...           0  \n",
       "47751  Sorry about that! Please ignore my email.\\r\\n\\...           1  \n",
       "35840  Ya Ivywise sent me a list of their coaches and...           1  \n",
       "496                                                                0  \n",
       "39366  Hi Vineet,\\r\\n\\r\\nLooks like the venmo payment...           1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show 20 random emails\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject        object\n",
       "Sender         object\n",
       "Date          float64\n",
       "Body           object\n",
       "Replied To      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the labels column\n",
    "df = df.drop(columns=['Labels'])\n",
    "\n",
    "#show the datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Subject: VINEET, Remember To Purchase Your Get...\n",
      "1        Subject: Spring Recital next Saturday May 20th...\n",
      "2        Subject: [Class of 2028] Save the date - 7th G...\n",
      "3        Subject: [Mantri Celestia] Special Notice: Pow...\n",
      "4        Subject: We're Giving You Up to 40% Off Sale S...\n",
      "                               ...                        \n",
      "57826    Subject: Re: ITR for AY 2021-22 Body: Dear Sir...\n",
      "57888    Subject:  Body: Last chance to get up to 80% o...\n",
      "57971    Subject:  Body: Up to 80% off ends soon! Shop ...\n",
      "58063    Subject:  Body: On-sale upgrades for every roo...\n",
      "58123    Subject: Re: ITR for AY 2021-22 Body:  Sender:...\n",
      "Length: 1740, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import TextVectorization, Normalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "numerical_data = df['Date']\n",
    "labels = df['Replied To']\n",
    "\n",
    "#concatenate all of the textual data into one string for each email\n",
    "textual_data = 'Subject: ' + df['Subject'] + ' Body: ' + df['Body'] + ' Sender: ' + df['Sender']\n",
    "\n",
    "#vectorize the textual data\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200, output_mode='int')\n",
    "vectorizer.adapt(textual_data)\n",
    "\n",
    "#normalize the numerical data\n",
    "normalizer = Normalization(axis=None)\n",
    "normalizer.adapt(numerical_data)\n",
    "\n",
    "features = tf.data.Dataset.from_tensor_slices((textual_data.values, numerical_data.values))\n",
    "labels = tf.data.Dataset.from_tensor_slices(labels.values)\n",
    "dataset = tf.data.Dataset.zip((features, labels))\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=10000).batch(32)\n",
    "\n",
    "#show the setup of the dataset\n",
    "for batch in dataset.take(1):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization_11 (TextVec  (None, 200)         0           ['text[0][0]']                   \n",
      " torization)                                                                                      \n",
      "                                                                                                  \n",
      " embedding_14 (Embedding)       (None, 200, 256)     5120000     ['text_vectorization_11[4][0]']  \n",
      "                                                                                                  \n",
      " num (InputLayer)               [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " lstm_15 (LSTM)                 (None, 256)          525312      ['embedding_14[0][0]']           \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 128)          256         ['num[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 384)          0           ['lstm_15[0][0]',                \n",
      "                                                                  'dense_25[0][0]']               \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 1)            385         ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,645,953\n",
      "Trainable params: 5,645,953\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build a model\n",
    "\n",
    "text_input = keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
    "num_input = keras.Input(shape=(1,), dtype=tf.float32, name='num')\n",
    "\n",
    "#make a large model, since the data in each email is large\n",
    "embedding = layers.Embedding(input_dim=20000, output_dim=256, mask_zero=True)(vectorizer(text_input))\n",
    "lstm = layers.LSTM(256)(embedding)\n",
    "dense = layers.Dense(128, activation='relu')(num_input)\n",
    "concat = layers.Concatenate()([lstm, dense])\n",
    "output = layers.Dense(1, activation='sigmoid')(concat)\n",
    "\n",
    "model = keras.Model(inputs=[text_input, num_input], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 25s 413ms/step - loss: 49.8036 - accuracy: 0.7603 - lr: 3.8147e-09\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 23s 420ms/step - loss: 50.2230 - accuracy: 0.7621 - lr: 3.8147e-09\n",
      "Epoch 3/50\n",
      "55/55 [==============================] - 23s 410ms/step - loss: 50.0187 - accuracy: 0.7609 - lr: 3.8147e-09\n",
      "Epoch 4/50\n",
      "55/55 [==============================] - 23s 419ms/step - loss: 50.3729 - accuracy: 0.7586 - lr: 3.8147e-09\n",
      "Epoch 5/50\n",
      "55/55 [==============================] - 24s 445ms/step - loss: 49.9159 - accuracy: 0.7638 - lr: 3.8147e-09\n",
      "Epoch 6/50\n",
      "55/55 [==============================] - 25s 444ms/step - loss: 50.0121 - accuracy: 0.7609 - lr: 3.8147e-09\n",
      "Epoch 7/50\n",
      "55/55 [==============================] - 23s 424ms/step - loss: 50.4469 - accuracy: 0.7632 - lr: 3.8147e-09\n",
      "Epoch 8/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 49.9764 - accuracy: 0.7609\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "55/55 [==============================] - 23s 425ms/step - loss: 49.9764 - accuracy: 0.7609 - lr: 3.8147e-09\n",
      "Epoch 9/50\n",
      "55/55 [==============================] - 23s 423ms/step - loss: 49.9707 - accuracy: 0.7592 - lr: 1.9073e-09\n",
      "Epoch 10/50\n",
      "55/55 [==============================] - 25s 450ms/step - loss: 49.8086 - accuracy: 0.7615 - lr: 1.9073e-09\n",
      "Epoch 11/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 49.7243 - accuracy: 0.7638\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "55/55 [==============================] - 25s 458ms/step - loss: 49.7243 - accuracy: 0.7638 - lr: 1.9073e-09\n",
      "Epoch 12/50\n",
      "55/55 [==============================] - 23s 414ms/step - loss: 49.6465 - accuracy: 0.7632 - lr: 9.5367e-10\n",
      "Epoch 13/50\n",
      "55/55 [==============================] - 23s 425ms/step - loss: 49.6855 - accuracy: 0.7638 - lr: 9.5367e-10\n",
      "Epoch 14/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 49.6246 - accuracy: 0.7638\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "55/55 [==============================] - 23s 413ms/step - loss: 49.6246 - accuracy: 0.7638 - lr: 9.5367e-10\n",
      "Epoch 15/50\n",
      "55/55 [==============================] - 23s 415ms/step - loss: 49.6192 - accuracy: 0.7638 - lr: 4.7684e-10\n",
      "Epoch 16/50\n",
      "55/55 [==============================] - 23s 421ms/step - loss: 49.6193 - accuracy: 0.7638 - lr: 4.7684e-10\n",
      "Epoch 17/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 49.6178 - accuracy: 0.7638\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "55/55 [==============================] - 23s 425ms/step - loss: 49.6178 - accuracy: 0.7638 - lr: 4.7684e-10\n",
      "Epoch 18/50\n",
      "55/55 [==============================] - 24s 430ms/step - loss: 49.6170 - accuracy: 0.7638 - lr: 2.3842e-10\n",
      "Epoch 19/50\n",
      "55/55 [==============================] - 25s 451ms/step - loss: 49.6077 - accuracy: 0.7638 - lr: 2.3842e-10\n",
      "Epoch 20/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 49.6146 - accuracy: 0.7638\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "55/55 [==============================] - 25s 453ms/step - loss: 49.6146 - accuracy: 0.7638 - lr: 2.3842e-10\n",
      "Epoch 21/50\n",
      "55/55 [==============================] - 24s 442ms/step - loss: 49.6146 - accuracy: 0.7638 - lr: 1.1921e-10\n",
      "Epoch 22/50\n",
      "55/55 [==============================] - 26s 477ms/step - loss: 49.6169 - accuracy: 0.7638 - lr: 1.1921e-10\n",
      "Epoch 23/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 49.6147 - accuracy: 0.7638\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
      "55/55 [==============================] - 23s 427ms/step - loss: 49.6147 - accuracy: 0.7638 - lr: 1.1921e-10\n",
      "Epoch 24/50\n",
      "55/55 [==============================] - 24s 433ms/step - loss: 49.6146 - accuracy: 0.7638 - lr: 5.9605e-11\n",
      "Epoch 25/50\n",
      "55/55 [==============================] - 25s 455ms/step - loss: 49.6147 - accuracy: 0.7638 - lr: 5.9605e-11\n",
      "Epoch 26/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 49.6123 - accuracy: 0.7638\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n",
      "55/55 [==============================] - 24s 434ms/step - loss: 49.6123 - accuracy: 0.7638 - lr: 5.9605e-11\n",
      "Epoch 27/50\n",
      "55/55 [==============================] - 25s 450ms/step - loss: 49.6124 - accuracy: 0.7638 - lr: 2.9802e-11\n",
      "Epoch 28/50\n",
      "55/55 [==============================] - 23s 424ms/step - loss: 49.6123 - accuracy: 0.7638 - lr: 2.9802e-11\n",
      "Epoch 29/50\n",
      "55/55 [==============================] - ETA: 0s - loss: 49.6123 - accuracy: 0.7638\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n",
      "55/55 [==============================] - 24s 433ms/step - loss: 49.6123 - accuracy: 0.7638 - lr: 2.9802e-11\n",
      "Epoch 30/50\n",
      "55/55 [==============================] - 24s 438ms/step - loss: 49.6123 - accuracy: 0.7638 - lr: 1.4901e-11\n",
      "Epoch 31/50\n",
      "55/55 [==============================] - 24s 430ms/step - loss: 49.6124 - accuracy: 0.7638 - lr: 1.4901e-11\n",
      "Epoch 32/50\n",
      "22/55 [===========>..................] - ETA: 14s - loss: 49.3173 - accuracy: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m test \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mskip(\u001b[39m10000\u001b[39m)\n\u001b[0;32m      3\u001b[0m val \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mskip(\u001b[39m10000\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      6\u001b[0m     train,\n\u001b[0;32m      7\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval,\n\u001b[0;32m      8\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mReduceLROnPlateau(monitor\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, factor\u001b[39m=\u001b[39;49m\u001b[39m.5\u001b[39;49m)]\n\u001b[0;32m     10\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\aryav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train = dataset.take(10000)\n",
    "test = dataset.skip(10000)\n",
    "val = test.skip(10000)\n",
    "\n",
    "model.fit(\n",
    "    train,\n",
    "    validation_data=val,\n",
    "    epochs=50,\n",
    "    callbacks=[keras.callbacks.ReduceLROnPlateau(monitor='accuracy', patience=3, verbose=1, factor=.5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
